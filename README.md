# CYC+

## Reinforcement Learning (`marl_env.py`)

### Setting

+ Edge Server: $S=\{M_1, M_2, ... M_s\}$

### State

+ $State(t)=\{\{Q_i(t), A_i(t), EC_i(t), x_i^{cloud}, \{x_{i,j}(t)\}_{i \neq j} \}_{i=1}^s\}$

### Action
+ Single Agent: $\Gamma(t)=\{f_i(t), f_i^{cloud},\{p_{i,j}(t)\}_{, j\neq i},p_i^{cloud}(t),\{x_{i,j}(t)\}_{j\neq i},x_{i,c}(t)\}_{i=1}^{s}$
+ Multi Agent: $\Gamma_i(t)=\{f_i(t), f_i^{cloud}, \{p_{i,j}(t)\}_{j\neq i},p_i^{cloud}(t),\{x_{i,j}(t)\}_{i\neq j},x_{i,c}(t)\}$


### State Transition

+ Queue
  + Edge:
  + Cloud:
+ CPU-Cycle Frequence
  + Edge:
  + Cloud:
+ Transmission Power:
  + Edge:

###